---
title: 'HW4: Indexing & Ranking Webpages'
author: "asif zubair"
date: "April 9, 2017"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

\tableofcontents

## Solr

Solr core was created and crawled data (from NBC News) was indexed and required changes were made to `managed-schema` and `solrconfig.xml`. 

The following commands were run on solr to create the core:
```shell
solr start
solr create -c NBCNews2
```

The following entries were made to `managed-schema`:
```xml
<field name="id" type="string" indexed="true" stored="true" required="true" multiValued="false" />
<field name="_version_" type="long" indexed="true" stored="true" />
<field name="_root_" type="string" indexed="true" stored="false" />
<field name="_text_" type="text_general" indexed="true" stored="false" multiValued="true" />
<copyField source="*" dest="_text_" />
```

Thereafter, the webpages were indexed using the following command:
```shell
post -c NBCNews2 -filetypes html data/NBCNewsData/NBCNewsDownloadData
```

`solrconfig.xml` was edited in order to define the default field in the `requestHandler` to be `_text_`:
```xml
<requestHandler name="/select" class="solr.SearchHandler">
<lst name="defaults">
  <str name="echoParms">explicit</str>
  <int name="rows">10</int>
  <str name="df">_text_</str>
</lst>
```

The core must be reloaded after this operation. This can be accomplished by either going to the `Solr Dashboard UI > Core Admin` and then clicking on `Reload` button or simply running this HTTP request: [http://localhost:8983/solr/admin/cores?action=RELOAD&core=NBCNews2](http://localhost:8983/solr/admin/cores?action=RELOAD&core=NBCNews2)

## Solr Php Client

With the Solr server up and accepting requests, we decided to interact with it using the php client available at this [github repository](https://github.com/PTCInc/solr-php-client/tree/ecc04b532c60c81ff6d588948d016020452aaa0d). 

We first explain how the client is set up using hte `example.php` available in the Wiki of this repository. We assume that Apache is already installed on the machine.   

* Clone the client into a folder of your choice.
* Place the `example.php` file inside the reposiotory.
* Launch the php server: `php -S localhost:8000 -t solr-php-client/`

The client can then be accessed by going to [http://localhost:8000/example.php](http://localhost:8000/example.php).  

However, for our purposes we made the following stylistic and functional changes to `example.php`:

First, we want the results to show only certain information and the URL and title of the webpage to be clickable. In order to accomplish this, we made use of the map file provided which gives the URL for each file. These are loaded into a `associative-array` using the following code:

```php
$myFile = "../data/NBCNewsData/mapNBCNewsDataFile.csv";
$fh = fopen($myFile, 'r');
$theData = fread($fh, filesize($myFile));
$assoc_array = array();
$my_array = explode("\n", $theData);
foreach($my_array as $line) {
  $tmp = explode(",", $line);
  $assoc_array[$tmp[0]] = isset($tmp[1]) ? str_replace(array("\n","\r"), '', $tmp[1]) : null;
}
fclose($fh);
$codes = $assoc_array;
```
Solr uses the full path of the file as `id`, so we used the `associative-array` above to find the corresponding URL. Using this information, we now display the following for each search result:

* Title (Clickable)
* URL (Clickable)
* ID
* Description

The following code was used to accomplish this:
```php
<?php
  // iterate result documents
  foreach ($results->response->docs as $doc)
  {
?>
    <li>
    <table style="border: 1px solid black; text-align: left">
<?php
    // iterate document fields / values
    foreach ($doc as $field => $value){
      $key = htmlspecialchars($field, ENT_NOQUOTES, 'utf-8');
      if (gettype($value) != "array"){
        if ('id' === $key) {
          $id = htmlspecialchars($value, ENT_NOQUOTES, 'utf-8');
        } elseif ('description' === $key) {
          $desc = htmlspecialchars($value, ENT_NOQUOTES, 'utf-8');
        } elseif ('title' === $key) {
          $title = htmlspecialchars($value, ENT_NOQUOTES, 'utf-8');
        };
      }
    }
?>
    <tr>
      <th> <?php echo "Title"; ?> </th>
      <td> <?php echo '<a href="'.$codes[basename($id)].'" target="_blank">'.$title.'</a>'; ?>
      </td>
    </tr>
    <tr>
      <th> <?php echo "URL"; ?> </th>
      <td> <?php echo '<a href="'.$codes[basename($id)].'" target="_blank">'.$codes[basename($id)].'
        </a>'; ?>
      </td>
    </tr>
    <tr>
      <th> <?php echo "ID"; ?> </th>
      <td> <?php echo $id; ?> </td>
    </tr>
    <tr>          
      <th> <?php echo "Description"; ?> </th>
      <td> <?php echo $desc; ?> </td>
    </tr>
    </table>
    </li>
<?php
  }
?>
```

In addition to these changes, we added some additional parameters to the query to specify which ranking algorithm (Lucene or PageRank) to use. Radio buttons were created using the following code:
```php
<input type="radio" name="sort" value="lucene" checked> Lucene
<input type="radio" name="sort" value="pagerank"> PageRank
```
and input from them was used to define additional parameters, like so:
```php
if(isset($_GET['sort']) && $_GET['sort'] === "lucene") {
    $additionalParameters = array();
    $engine = "Lucene";
} else {
    $additionalParameters = array(
      'sort' => 'pageRankFile desc',
    );
    $engine = "PageRank";
} 
```
Finally, the edited `example.php` was renamed to `solr-client.php`, so that the client can be accessed by going to this URL: [http://localhost:8000/solr-client.php](http://localhost:8000/solr-client.php)

## PageRank

For this exercise, we also wanted to compare ranking algorithms. Solr by default uses Lucene to rank webpages. We also computed pagerank scores for all the webpages that have been crawled. 

This was accomplished by first parsing all the pages for outgoing links, looking up file name in the map file provided, and then making an edgelist for all connections. The edgelist was fed into a program to construct a directed graph from which all PageRank scores were computed. To implement this scheme, we used the python packages `BeautifulSoup4` and `Networkx`.

More specifically, the following `Networkx` code was used:
```python
import networkx as nx
import os

edge_list = "edgeList.txt"
G = nx.read_edgelist("edgeList.txt", create_using = nx.DiGraph())
pr = nx.pagerank(G, alpha = 0.85, personalization = None, max_iter = 30, 
	tol = 1e-06, nstart = None, weight = 'weight', dangling = None)

base = "/Users/asifzubair/projects/information_retrieval/solr/data/NBCNewsData/NBCNewsDownloadData/"
with open('external_pageRankFile.txt', 'w') as out_file:
	for key, value in pr.items():
		out_file.write(os.path.join(base, key) + "=" + str(value) + "\n")
```
This code produced a file called `external_pageRankFile.txt` that had entries of the form `docId=PageRank`. This file was copied into the `conf` of the `Solr` core. 

Having produced the PageRank scores, we now have to cofigure `Solr` to use them. For this purpose we made the following modifications:

* The following entries were added to `managed-schema`
```php
<fieldType name="external" keyField="id" defVal="0" class="solr.ExternalFileField" 
  valType="pfloat" />
<field name="pageRankFile" type="external" stored="false" indexed="false"/>
```
* Listeners were defined with the `<query>` element of `solrconfig.xml`
```php
<listener event="newSearcher" class="org.apache.solr.schema.ExternalFileFieldReloader" />
<listener event="firstSearcher" class="org.apache.solr.schema.ExternalFileFieldReloader" />
```

The core was reloaded after these changes.

## Queries

The following queries were run with both PageRank and Solr default ranking algorithm:

* Brexit
* NASDAQ
* NBA
* Snapchat
* Illegal Immigration
* Donald Trump
* Russia
* NASA

We found overlaps only for "NASDAQ" and "NBA". Below, we plot the overlap between the top 10 results produced by the two ranking algorithms for these queries:

```{r, echo = F}
df = data.frame("NASDAQ"=3, "NBA"=1)
barplot(as.matrix(df), col = "darkblue", xlab = "Queries", ylab = "Number of Overlaps")
```


The lack of consistent overlap is surprising but it could be because the ranking algorithms are fundamentally different. Lucene uses a combination of the vector space model and the boolean model to determine how relevant a given document is to a user's query. The vector space model is based on term frequency. However, PageRank works by counting the number an quality of links to a page to detemerine a roughly how important a website is. This means that the ranking difference is also reflective of how connected the node (webpage) is in the graph.

